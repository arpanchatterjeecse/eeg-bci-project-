{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1eb02f",
   "metadata": {
    "papermill": {
     "duration": 0.002502,
     "end_time": "2025-05-22T16:23:41.733598",
     "exception": false,
     "start_time": "2025-05-22T16:23:41.731096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4342d3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T16:23:41.739985Z",
     "iopub.status.busy": "2025-05-22T16:23:41.739546Z",
     "iopub.status.idle": "2025-05-22T16:23:45.842023Z",
     "shell.execute_reply": "2025-05-22T16:23:45.840914Z"
    },
    "papermill": {
     "duration": 4.108284,
     "end_time": "2025-05-22T16:23:45.844079",
     "exception": false,
     "start_time": "2025-05-22T16:23:41.735795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "  Train:      (6900, 178, 1)\n",
      "  Validation: (2300, 178, 1)\n",
      "  Test:       (2300, 178, 1)\n",
      "Class weights: {0: 0.625, 1: 2.5}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"/kaggle/input/epileptic-seizure-recognition/Epileptic Seizure Recognition.csv\")\n",
    "\n",
    "# 2. Drop index column if present\n",
    "if 'Unnamed' in df.columns:\n",
    "    df.drop('Unnamed', axis=1, inplace=True)\n",
    "\n",
    "# 3. Convert multiclass to binary:\n",
    "# Class 1 = seizure (label 1), Classes 2–5 = non-seizure (label 0)\n",
    "df['y_binary'] = (df['y'] == 1).astype(int)\n",
    "\n",
    "# 4. Define feature columns and extract data\n",
    "feature_cols = [f'X{i}' for i in range(1, 179)]  # X1 to X178\n",
    "X = df[feature_cols].values                     # Shape: (11500, 178)\n",
    "y = df['y_binary'].values                       # Shape: (11500,)\n",
    "\n",
    "# 5. Standardize features (mean 0, std 1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 6. Reshape for RNN input: (samples, timesteps, features_per_timestep)\n",
    "# Here: each sample has 178 timesteps, 1 feature per timestep\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)  # (11500, 178, 1)\n",
    "\n",
    "# 7. Split data: 60% train, 20% validation, 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_reshaped, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42)\n",
    "\n",
    "# 8. Compute class weights for imbalanced data\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 9. Print shapes and weights\n",
    "print(\"Data shapes:\")\n",
    "print(f\"  Train:      {X_train.shape}\")\n",
    "print(f\"  Validation: {X_val.shape}\")\n",
    "print(f\"  Test:       {X_test.shape}\")\n",
    "print(f\"Class weights: {class_weight_dict}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e734f1b",
   "metadata": {
    "papermill": {
     "duration": 0.001983,
     "end_time": "2025-05-22T16:23:45.848628",
     "exception": false,
     "start_time": "2025-05-22T16:23:45.846645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Complex RNN**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3bf3486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T16:23:45.854374Z",
     "iopub.status.busy": "2025-05-22T16:23:45.854061Z",
     "iopub.status.idle": "2025-05-22T16:24:03.575645Z",
     "shell.execute_reply": "2025-05-22T16:24:03.574631Z"
    },
    "papermill": {
     "duration": 17.726572,
     "end_time": "2025-05-22T16:24:03.577339",
     "exception": false,
     "start_time": "2025-05-22T16:23:45.850767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 16:23:48.336106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747931028.587208      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747931028.659254      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(\n",
    "        LSTM(hp.Int('lstm_units1', min_value=32, max_value=128, step=16),\n",
    "             return_sequences=True, activation='tanh'),\n",
    "        input_shape=(178, 1)\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout1', 0.2, 0.5, step=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Bidirectional(\n",
    "        LSTM(hp.Int('lstm_units2', min_value=16, max_value=64, step=16),\n",
    "             activation='tanh')\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout2', 0.2, 0.5, step=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(hp.Int('dense_units', 32, 128, step=32), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout3', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('lr', [1e-3, 1e-4, 5e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15231207",
   "metadata": {
    "papermill": {
     "duration": 0.001926,
     "end_time": "2025-05-22T16:24:03.581634",
     "exception": false,
     "start_time": "2025-05-22T16:24:03.579708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bayesian Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac96eccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T16:24:03.587347Z",
     "iopub.status.busy": "2025-05-22T16:24:03.586778Z",
     "iopub.status.idle": "2025-05-22T21:05:48.638165Z",
     "shell.execute_reply": "2025-05-22T21:05:48.637072Z"
    },
    "papermill": {
     "duration": 16905.055853,
     "end_time": "2025-05-22T21:05:48.639649",
     "exception": false,
     "start_time": "2025-05-22T16:24:03.583796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 15m 08s]\n",
      "val_accuracy: 0.9817391037940979\n",
      "\n",
      "Best val_accuracy So Far: 0.9817391037940979\n",
      "Total elapsed time: 04h 35m 07s\n",
      "Best hyperparameters: {'lstm_units1': 32, 'dropout1': 0.30000000000000004, 'lstm_units2': 64, 'dropout2': 0.30000000000000004, 'dense_units': 96, 'dropout3': 0.4, 'lr': 0.0005}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 174ms/step - accuracy: 0.9809 - loss: 0.0536 - val_accuracy: 0.9787 - val_loss: 0.0670\n",
      "Epoch 2/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step - accuracy: 0.9817 - loss: 0.0439 - val_accuracy: 0.9761 - val_loss: 0.0800\n",
      "Epoch 3/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 168ms/step - accuracy: 0.9855 - loss: 0.0391 - val_accuracy: 0.9796 - val_loss: 0.0780\n",
      "Epoch 4/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step - accuracy: 0.9818 - loss: 0.0507 - val_accuracy: 0.9800 - val_loss: 0.0771\n",
      "Epoch 5/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 169ms/step - accuracy: 0.9853 - loss: 0.0408 - val_accuracy: 0.9813 - val_loss: 0.0658\n",
      "Epoch 6/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 169ms/step - accuracy: 0.9872 - loss: 0.0399 - val_accuracy: 0.9765 - val_loss: 0.0857\n",
      "Epoch 7/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 169ms/step - accuracy: 0.9851 - loss: 0.0431 - val_accuracy: 0.9800 - val_loss: 0.0722\n",
      "Epoch 8/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 171ms/step - accuracy: 0.9867 - loss: 0.0344 - val_accuracy: 0.9809 - val_loss: 0.0740\n",
      "Epoch 9/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 169ms/step - accuracy: 0.9837 - loss: 0.0409 - val_accuracy: 0.9770 - val_loss: 0.0750\n",
      "Epoch 10/30\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 169ms/step - accuracy: 0.9825 - loss: 0.0396 - val_accuracy: 0.9813 - val_loss: 0.0810\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step\n",
      "Training Accuracy:   0.9877\n",
      "Validation Accuracy: 0.9813\n",
      "Test Accuracy:       0.9800\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# 2. Setup tuner\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    directory='seizure_tuning',\n",
    "    project_name='rnn_seizure_detection'\n",
    ")\n",
    "\n",
    "# 3. Early stopping\n",
    "stop_early = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 4. Hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=30,\n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[stop_early],\n",
    "             batch_size=32)\n",
    "\n",
    "# 5. Get best model and best hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best hyperparameters:\", best_hp.values)\n",
    "\n",
    "# 6. Retrain on train+val data (optional)\n",
    "best_model.fit(X_train, y_train,\n",
    "               epochs=30,\n",
    "               validation_data=(X_val, y_val),\n",
    "               batch_size=32,\n",
    "               callbacks=[stop_early])\n",
    "\n",
    "# 7. Accuracy evaluation\n",
    "train_preds = (best_model.predict(X_train) > 0.5).astype(int)\n",
    "val_preds = (best_model.predict(X_val) > 0.5).astype(int)\n",
    "test_preds = (best_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(f\"Training Accuracy:   {train_acc:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy:       {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 63117,
     "sourceId": 122455,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16934.71637,
   "end_time": "2025-05-22T21:05:51.598752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T16:23:36.882382",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
